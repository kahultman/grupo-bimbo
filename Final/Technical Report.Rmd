---
title: "Grupo Bimbo Technical Report"
subtitle: "Predicting Demand of Bakery Goods"
author: "Keith Hultman, Carolyn Meier, Renjith Madhavan"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: TRUE
    
---

```{r setup, include=FALSE}
library(dplyr)
library(grid)
library(ggplot2)
setwd("~/github/grupo-bimbo/Final/")
source("base_scripts.R")
```

# Grupo Bimbo Technical Report

## Project Overview

Our client, Grupo Bimbo, wants to develop a model to accurately forecast inventory demand based on the historical sales data they collect. Grupo Bimbo is a large bakery store chain that has more than 2500 products spanning over one million stores. Their goal is to meet the product demand for their customers while minimizing unsold surplus. Our group is tasked to create a model to accurately forecast inventory demand based on the historical sales data provided. Creating a successful model will give each of the 1 million stores the ability to accurately request the appropriate amount of each bakery product on a weekly basis.
  Grupo Bimbo's current model for estimating demand is purely human estimated. Managers estimate demand from the sales of products and their returns and make a judgement for the following week's orders. This 'human' model offers a very high business value for implementing automated machine learning and data science methods to more accurately predict demand. 

### Description of data and competition rules

Grupo Bimbo supplied 9 weeks of historical data in a 3.2Gb csv file with 74,180,464 weekly observations for each product delivery. The features in the training data set, and the features available in the test set are detailed below.  

|Field|Original name |Description|In test set
|----------------|------------|-----------------------|---------|
|week |Semana|Week number (3-9)|+|
|depot |Agencia_ID|Sales Depot ID|+
|channel |Canal_ID|Sales Channel ID|+
|route |Ruta_SAK|Route ID (Several routes / Sales Depot)|+
|client |Cliente_ID|Client or Store ID|+
|product |Producto_ID|Product ID|+
|sales_units |Venta_uni_hoy|Sales units this week|
|sales |Venta_hoy|Sales this week (pesos)|
|returns_units |Dev_uni_proxima|Returns units next week|
|returns |Dev_proxima|Returns next week (pesos)|
|demand|Demanda_uni_equil|Adjusted Demand (sales_units - returns_units)|

  The target variable is ‘Adjusted Demand’, which will be an integer representing the demand of a product, in units. 
  Each model will be evaluated for accuracy using the Root Mean Squared Logarithmic Error (RMSLE). This measure for estimating error will penalize models that under-predict more than a model that over-predicts. 

$$\epsilon = \sqrt{\frac{1}{n} \sum_{i=1}^{n} \big(log(p_i + 1)-log(a_i + 1)\big)^2}$$

Where:

$\epsilon$ is the RMSLE value (score)

$n$ is the total number of observations in the data set,

$p_i$ is the prediction of demand

$a_i$ is the actual demand for $i$

$log(x)$ is the natural logarithm of $x$

  
  Another limitation of this data set is that demand is approximated by subtracting the supply from the following week's return of inventory. This would naturally allow for an accurate estimate of demand when supply is higher than demand, but would not accurately estimate demand in cases where the product is under-supplied. Using RMSLE helps with this in some ways by having a greater cost for under-estimated demand than over-estimated demand. However, this alone would not guarentee accurate model evaluation with true demand. 

### Data Science Plan and Process

![CRISP](crisp_model_4by4.png) 

Our team of data scientists will be using the CRISP method of data science. 
This technical report will mirror the data science steps outlined in CRISP. We primarily used R for the visualization and modeling processes. Version control and collaboration was done by using a [github repository](https://github.com/kahultman/grupo-bimbo), and our code is available there. Communication between group members was primarily using Slack and a weekly Google Hangouts video conference. 


## Data Exploration 1

During the initial data exploration step, each of us independently explored the data using summary statistics and visualizations. 

```{r}

```


### Goals for the Kaggle competition versus actual client work

Since our project was based off of a Kaggle competition, it is worth pointing out how the competition rules shaped and limited our approach to the project. If our project were a real-world situation, our model would be deployed to predict demand for Grupo Bimbo's products and we would be able to evaluate how well our predicted demand matched the actual demand for the products based on the number of returns the company observed following deployment. For example if our model predicted an increase in demand for product #384 at store #1381 from 15 units to 20 units, Grupo Bimbo would increase the sales to that store and record the number of returned units the following week. However, since both the train and the test data sets are historical, the actual recorded demand is based off of sales without deploying our model. In other words, the cake is already baked and the record for demand is actually based in part on the current human model of demand.  

Only 3% of weekly product sales involve any returned products. If the human model is responsive to these returns we expect to see a drop in the following week's deliveries. However, as Figure 1A and 1B show, it looks like the human model is not responsive to a product with returns or the number of returned units. We consider this beneficial for our purposes because we can estimate actual demand rather than attempt to predict the behavior of the current human model. There is an effect on actual demand however (Fig 1C, 1D), so there is a small benefit to be gained by incorporating returns within our models. 

```{r Responsiveness of Human model, eval=FALSE, message=TRUE, warning=FALSE, include=FALSE}
setwd("/Volumes/Half_Dome/datasets/grupo-bimbo/")
load("sampled_returns.Rdata")

plot1 <- ggplot(sampled, aes(x=has_return, y= sales_lead_delta)) + 
  geom_boxplot() + 
  ggtitle("A) Comparison of product with and \n without returns on following \n week's supply") +
  ylab("Change in Sales (week x+1 - week x)") +
  xlab("Previous week had return")

plot2 <- ggplot(sampled, aes(log(returns_units), sales_lead_delta)) + 
  geom_point() + 
  stat_smooth() +
  ggtitle("B) Effect of number of returns from \n previous week on following \n weeks supply") +
  ylab("Change in Sales") +
  xlab("Number of units returned \n in previous week (Log scale)")

plot3 <- ggplot(sampled, aes(x=had_return, y= demand)) + 
  geom_boxplot() + 
  ggtitle("C) Comparison of product with and \n without returns on following \n week's demand") +
  ylab("Change in Demand") +
  xlab("Previous week had return")

plot4 <- ggplot(sampled, aes(log(returns_units), demand_lead_delta)) + 
  geom_point() + 
  stat_smooth() +
  ggtitle("D) Effect of number of returns from \n previous week on following \n weeks demand") +
  ylab("Change in Demand") +
  xlab("Number of units returned \n in previous week (Log scale)")

multiplot(plot1, plot2, plot3, plot4, cols=2)

setwd("~/github/grupo-bimbo/Final/")
```



After model implementation, products should be intentionally overstocked if the product's demand is evaluated by data with no returns. 

![Sample Demand Over Time](sample_time_trend_6by6.png)

## Modelling 1: Persistant Baseline Model

Before implementing various machine learning methods we created a baseline model designed to predict demand based on minimal data and simulating the description of the human model currently in place at Grupo Bimbo. In this model, demand is assumed to remain unchanged from the previous week. In the case where a product/client combination is new or there is a newly released product, demand is predicted to be the overall mean demand.

Persistant Baseline Model: Demand(week^x^) = Demand(week^x-1^)

RMSLE: 

## Data Exploration 2

```{r}

```


## Modelling 2: Conditional Medians

### Conditional Means 1
1. Demand = median {PC}
2. Demand = median {P}
3. Demand = median all products

RMSLE score of 0.50941

### Conditional Means 2
1. Demand = median {PCD}
2. Demand = median {PC}
3. Demand = median {P}
4. Demand = median all products

RMSLE score of 0.50922


### CLRM: Conditional Linear Regression of Means

Our next model is a more complex version of the conditional medians model with two major additional changes. The first is that for the most specific cases where product, client, and depot are all a match, we implement a linear regression model that includes a component for that specific case as well as for the more general case of product and route. The second modification involves transforming our target variable from demand to the logarithm of demand plus 1. 


1. $log(Demand)$ = 0.9994$log(\mu{PCD})$ + 1.094e-03$log(\mu{PR})$ - 7.672e-04 
2. $log(Demand)$ = $log(\mu{PR})$ - 6.153e-13$log(\mu{P})$ + 6.785e-10
3. $log(Demand)$ = $log(\mu{P})$
4. $log(Demand)$ = $log(\mu{all})$

RMSLE score of 0.48943

## Feature Engineering

Feature engineering was very important in extracting new fields for improving the model. We were able to extract the below features from the given data sets.

1. Product Brand
2. Product Weight
3. Product number of pieces

## Modelling 3: XGBoost

Suggestions to Grupo Bimbo for further data mining value

* Better Data Collection
* Clustering on products - Currently if a new product is in the test set, we have to use the overall product average in the CLRM model. If we had products clustered by product attributes and similar demand patterns, we could improve predictions for newly released products. 
