---
title: "data_exploration"
author: "Keith Hultman"
date: "June 13, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(data.table)
library(feather)
library(ggplot2)
```
# Load Data

```{r}
setwd("/Volumes/Half_Dome/datasets/grupo-bimbo/")
load("train1.Rdata")
load("train2.Rdata")
load("validate.Rdata")
load("test.Rdata")
load("clients.Rdata")
load("products.Rdata")
load("town_state.Rdata")


```

# Products missing in the train set that are in the kaggle test set
The kaggle page mentioned that there will be products in the test set that were not in the train set
```{r}

train1_products <- unique(train1$product)

test_products <- unique(test$product)

#Train products missing from test products
train1_products[!(train1_products %in% test_products)]

# Test products missing from train products
new_products <- as.data.frame(test_products[!(test_products %in% train1_products)])
colnames(new_products) <- c("product")

new_products <- new_products %>%
  left_join(products, by = "product")

# Number of products in test set missing in full training set:
nrow(new_products)
```

# What about for our split data? Are there any products missing in train2 that are in the validate test set?

```{r}

validate_products <- unique(validate$product)
train2_products <- unique(train2$product)


#Train2 products missing from validate products
train2_products[!(train2_products %in% validate_products)]

# Validate products missing from train2 products
new_validate_products <- as.data.frame(validate_products[!(validate_products %in% train2_products)])
colnames(new_validate_products) <- c("product")

new_validate_products <- new_validate_products %>%
  left_join(products, by = "product")

new_validate_products 

# Number of products in our validate test set that are not in our train2 data. We will need to have a naive model for new products. 
nrow(new_validate_products)
```

This is good. We will be able to test how our model works for new products

# From now on, only look at Train2 data set
## Summarize Data

```{r}
# train2
train2
# validate
validate
# clients file
clients
# products file
products
# town_state file
town_state

# Weeks in training data set and number of samples per week
train2 %>% 
  group_by(week) %>%
  summarise(Number = n())

# Weeks and samples in the validate set
validate %>%
  group_by(week) %>%
  summarise(Number = n())

# Unique variables in train2 dataset
train2 %>% summarise(Depots = n_distinct(depot), Channels = n_distinct(channel), Routes = n_distinct(route), Clients = n_distinct(client), Products = n_distinct(product))

```

# Let's look at trends of random products across all clients. 
I was wondering if there were some patterns of demand that crossed all stores. 

```{r Some Visualizations}
set.seed(65)
product_sample <- products %>% sample_n(15)
product_sample

# Scatterplot of sample products
# train2 %>% 
#   filter(product %in% product_sample$product) %>%
#   ggplot(aes(x = week, y = demand)) +
#   geom_point() +
#   facet_wrap(~ product, scale = "free_y")

# Trend lines of average demand over time for sample products
product_trend_sample <- train2 %>% 
  filter(product %in% product_sample$product) %>%
  group_by(product, week) %>%
  summarise(ave_demand = mean(demand))
  
product_trend_sample  

ggplot(product_trend_sample, aes(x = week, y = ave_demand)) +
  geom_point() +
  stat_smooth() +
  facet_wrap(~ product, scale = "free_y")

# Looking at the trend of one of those products, 5710
product5710 <- train2 %>% 
  filter(product == 5710) 
  
ggplot(product5710, aes(x = week, y = demand)) +
  geom_point() +
  stat_smooth() +
  ggtitle("Demand for Product 5710")

store_sample <- sample_n(as.data.frame(unique(product5710$client)), 9)
colnames(store_sample) <- "clientsample"

product5710_store_sample <- product5710 %>%
  filter(client %in% store_sample$clientsample)

ggplot(product5710_store_sample, aes(x = week, y = demand)) +
  geom_point() +
  facet_wrap(~client) +
  ggtitle("Sample of stores for Product 5710")

```

